This folder contains all the code necessary for performing the semantic modelling experiments described by McGregor and McGillivray (2018).  The scripts are as follows:

 - cleaner: takes a directory containing a corpus as input and outputs a cleaned up version formatted for subsequent modelling

 - contexter: builds a dynamically contextual base space from the output of cleaner

 - wtver: builds a word2vec model from the output of cleaner

 - worder: builds a list of words associated with various modelling parameters that are expected to indicate the prsence of a semantic phnonmenon associated with an input list of canonical semantic queues (eg, words that indicate a sentence is about smell in the research from McGregor and McGillivray)

 - proby.py: supports the dynamically contextual modelling for the worder script

 - wtouty.py: supports the static (word2vec) modelling for the worder script

 - outputter: builds a matrix of binary classifications for the presence of smell for each sentence is a list of sentences (presumed to be accompanied by human gold standard ratings) for the lists of words output by the worder script, applying a set of different techniques for interpreting each list

 - reducer: eliminates uninformative columns from the matrix generated by the outputter script

 - multimodeller: performs multi-variable logistic regression on the scores generated by the outputter script and refined by the reducer script

Some additional details are provided at the beginning of each script.
