#This script expects as input the lists of candidate smell words generated by the "worder" script (variable "ft") as well as a list of human judgements of sentence-by-sentence smell ratings (variable "fr").  The file "fr" should be formatted as a csv, with one sentence per line followed by a comma followed by a 0 or a 1 indicating the absence or presence of the semantic feature being modelled.  This can be followed by any other information involved in the human analysis of the corpus; only the first two values per line will be analysed.  If the sentence itself contains commas, then the sentence should be enclosed in double quotation marks.  This script will handle any other punctuation contained in the sentence.  It will output a new file (variable "fw") in which each line begins with a sentence, followed by a triple-colon (":::"), followed by the human score, and then the score associated with each combination of modelling parameters likewise separated by triple-colons.

#The code will apply five different criteria for determining the presence of the semantic phenomenon being modelled (eg, smell) for each sentence, as outlined in the McGregor and McGillivray (2018).

fr = '/path/to/human/scores.csv'
ft = '/path/to/word/lists'
fw = '/path/to/model/scores'

import spacy
import re
import io

dep = spacy.load('en')

def reader(f):
#    ftr = open(f,'r').readlines()
    ftr = io.open(f,'r',encoding='utf-8').readlines()
    data = []
    for line in ftr:
        if line[0] == '"':
            data.append([line.split('",')[0][1:]] + line.split('",')[1].split(","))
        else:
            data.append(line.split(","))
    for n in range(len(data)):
        if data[n][1] == "":
            data[n][1] == "0"
        elif data[n][1] != "0":
            data[n][1] = "1"
    return data

def assesser(data,ftw,thr):
    tests = [x.split("::") for x in open(ft,'r').readlines()]
    sults = [x[:2] for x in data]
    thing = [[x[0]+"one",x[0]+"two",x[0]+"r-one",x[0]+"r-two",x[0]+"dep"] for x in tests]
    zing = [x for y in thing for x in y]
    sults[0] = sults[0] + zing
    ftw.write(":::".join(sults[0]) + "\n")
    for n in range(1,len(sults)):
        print(n)
        comp = re.sub("[:;,\"\*\[\]\(\)#}{\.]","",sults[n][0])
        comp = re.sub("( \')|(\' )"," ",comp)
        comp = re.sub("( -)|(- )"," ",comp)
        coms = comp.lower().split()
        parse = dep(unicode(comp))
        put = []
        for item in tests:
            words = [unicode(x.decode('utf-8')) for x in item[1].split(",")]
            simp = len([x for x in coms if x in words])
            par = 0
            for word in parse:
                if word.lemma_.lower() in words:
                    for child in [x for x in word.children]:
                        if child.lemma_.lower() in words:
                            par = 1
            put.extend([str(int(simp>0)),str(int(simp>1)),str(int(float(simp)/len(parse)>=thr)),str(int(float(simp)/len(parse)>=2*thr)),str(int(par==1))])
        ftw.write(":::".join([x.encode('utf-8') for x in sults[n]] + put ) + "\n")
    return sults

def writer(sults,ftw):
    ftw.write("\n".join([":::".join(x) for x in sults]))

data = reader(fr)
ftw = open(fw,'w')
sults = assesser(data,ftw,0.05)
